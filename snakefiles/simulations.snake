import numpy as np
import json
import gzip

from twosfs.config import configuration_from_json, parse_parameter_string
from twosfs.simulations import filename2seed, simulate_spectra
from twosfs.spectra import add_spectra, load_spectra, spectra_from_hdf5
from twosfs.statistics import (
    search_recombination_rates_save,
    degenerate_pairs,
    sample_spectra,
    sample_ks_statistics,
    sample_ks_statistics_save,
)

import time

config = configuration_from_json("simulation_parameters.json")


rule simulate_initial_spectra_all:
    input:
        list(config.initial_spectra_files()),
    resources:
        time=5,
        mem=100,

rule fit_demographies_all:
    input:
        list(config.fitted_demography_files()),
    resources:
        time=5,
        mem=100,

rule search_recombination_all:
    input:
        list(config.recombination_search_files()),
    resources:
        time=5,
        mem=100,

rule fitted_spectra_all:
    input:
        list(config.fitted_spectra_files()),
    resources:
        time=5,
        mem=100,

rule ks_distances_all:
    input:
        list(config.ks_distance_files()),
    resources:
        time=5,
        mem=100,

rule simulate_initial_spectra:
    output:
        temp(config.initial_spectra_file),
    wildcard_constraints:
        rep="\d+",
    resources:
        time=20,
        mem=1000,
    run:
        spectra = simulate_spectra(
            model=wildcards.model,
            model_parameters=parse_parameter_string(wildcards.params),
            msprime_parameters=config.msprime_parameters,
            scaled_recombination_rate=config.scaled_recombination_rate,
            random_seed=filename2seed(output[0]),
        )
        spectra.save(output[0])


rule fit_demographies:
    input:
        config.initial_spectra_file.replace(".rep={rep}.", ".rep=all."),
    output:
        config.fitted_demography_file,
    resources:
        time=10,
        mem=1000,
    run:
        spectra = load_spectra(input[0])
        fit = spectra.fit_pwc_demography(
            folded=wildcards.folded == "True",
            k_max=config.k_max,
            num_epochs=config.num_epochs,
            penalty_coef=config.penalty_coef,
        )
        with open(output[0], "w") as f:
            f.write(fit.toJson())


rule search_recombination_rate:
    input:
        spectra_file=config.initial_spectra_file.replace(".rep={rep}.", ".rep=all."),
        demo_file=config.fitted_demography_file,
    output:
        config.recombination_search_file,
	config.ks_distance_file,
    resources:
        time=150,
        mem=500,
    run:
        rng = np.random.default_rng(filename2seed(output[0]))
        raw_spectra = load_spectra(input.spectra_file)
        with open(input.demo_file) as f:
            model_parameters = json.load(f)
        num_pairs = np.zeros(len(raw_spectra.windows)-1)
        num_pairs[0:int(wildcards.sequence_length)] = int(wildcards.pair_density)
        spectra_samp = sample_spectra(raw_spectra, num_pairs=num_pairs, rng=rng)
        sim_kwargs = dict(
            model="pwc",
            model_parameters=model_parameters,
            msprime_parameters=(
                config.msprime_parameters
                | {
                    "sequence_length": int(wildcards.sequence_length),
                    "num_replicates": config.search_num_replicates,
                }
            ),
            random_seed=rng,
        )
        distances = (np.arange(int(wildcards.sequence_length) // 3) + 1) * 3
        if wildcards.model == "sel":
            r_low, r_high = (config.slim_parameters["search_r_low"], config.slim_parameters["search_r_high"])
        else:
            r_low, r_high = (config.search_r_low, config.search_r_high)
        r, p, ks, ks_dist, h_l = search_recombination_rates_save(
            output[0],
            spectra_samp,
            config.k_max,
            distances,
            bool(wildcards.folded),
            sim_kwargs,
            r_low,
            r_high,
            config.search_iters,
	    config.power_num_samples,
	    num_pairs
        )
        rec_search_results = {
            "rec_rate": r,
            "p_value": p,
            "ks_distance": ks,
            "ks_distribution": list(ks_dist),
            "higher_lower": h_l,
        }
        with open(output[1], "w") as f:
            json.dump(rec_search_results, f)

rule add_runs:
    output:
        "{prefix}.rep=all.{ext}",
    input:
        expand(
            "{prefix}.rep={rep}.{ext}",
            rep=range(config.nruns),
            allow_missing=True,
        ),
    resources:
        time=10,
        mem=1000,
    run:
        total = add_spectra(load_spectra(infn) for infn in input)
        total.save(output[0])


"""
rule compute_ks_distances:
    output:
        config.ks_distance_file,
    input:
        rec_search_file=config.recombination_search_file,
    resources:
        time=10,
        mem=1000,
    run:
        with h5py.File(input.rec_search_file) as hf:
            spec_comp = spectra_from_hdf5(hf.get("spectra_target"))
            if dict(hf.get("spectra_high").attrs)["ks_distance"] < dict(hf.get("spectra_low").attrs)["ks_distance"]:
                spec_null = spectra_from_hdf5(hf.get("spectra_high"))
            else:
                spec_null = spectra_from_hdf5(hf.get("spectra_low"))
        distances = (np.arange(int(wildcards.sequence_length) // 3) + 1) * 3
        num_pairs = np.ones(int(wildcards.sequence_length)) * int(wildcards.pair_density)
        sample_ks_statistics_save(
            spectra_null = spec_null,
            k_max = config.k_max,
            distances = distances,
            folded = wildcards.folded,
            n_reps = config.n_reps * config.nruns,
            num_pairs = num_pairs,
            output_file = output[0],
        )
"""

