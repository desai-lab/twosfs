import numpy as np
import json

from twosfs import load_spectra
from twosfs.simulations import parameter_map, filename2seed, simulate_spectra
from twosfs.demographicmodel import scaled_demographic_events
from twosfs.statistics import scan_parameters

nruns = 100
default_parameters = {
    'sample_size': 100,
    'length': 100,
    'recombination_rate': 0.1 / 4, # Scaled so that rT2 = 0.1 per site
    'num_replicates': 10000,
}

d_alpha = 0.05
ALPHAS = [f'{a:.2f}' for a in np.arange(1 + d_alpha, 2.0, d_alpha)]
GS = [f'{g:.1f}' for g in [0.5, 1.0, 2.0]]
TS = [f'{t:.1f}' for t in [0.5, 1.0, 2.0]]
RS = [f'{r:.2f}' for r in np.logspace(-1, 1, 4, base=2)] + ["1.00"]

prefixes = expand(["xibeta-alpha={alpha}", "expgrowth-g={g}-t={t}"], alpha=ALPHAS, g=GS, t=TS)
models = ['3Epoch']

rule compute_all_pvalues:
    input:
        expand("simulations/pvalues/{prefix}.{model}.rec={r_factor}.json",
               prefix=prefixes, model=models, r_factor=RS),
        expand("simulations/pvalues/{prefix}.{model}.json",
               prefix=prefixes, model=models, r_factor=RS)

rule simulate_models_recombination:
    input:
        expand("simulations/msprime/fastNeutrino.{prefix}.{model}.rec={r_factor}.npz",
               prefix=prefixes, model=models, r_factor=RS)

rule simulate_models:
    input:
        expand("simulations/msprime/fastNeutrino.{prefix}.{model}.npz",
               prefix=prefixes, model=models)

rule fit_models:
    input:
        expand("simulations/fastNeutrino/{prefix}.{model}.txt",
               prefix=prefixes, model=models)

rule initial_simulations:
    input:
        expand("simulations/msprime/{prefix}.npz", prefix=prefixes)

ruleorder: msprime_from_fastNeutrino_modified_recombination > msprime_from_fastNeutrino > msprime

rule msprime:
    output:
        temp('simulations/.tmp/{prefix}.rep{rep}.npz')
    run:
        parameters = parameter_map(wildcards.prefix, default_parameters)
        parameters['random_seed'] = filename2seed(output[0])
        spectra = simulate_spectra(parameters)
        spectra.save(output[0])

max_k = 20
pair_densities = [100, 1000, 10000]
max_ds = [2, 6, 11, 16]
n_reps = 1000

ruleorder: compute_pvalues_recombination > compute_pvalues

rule compute_pvalues:
    input:
        "simulations/msprime/{prefix}.npz",
        "simulations/msprime/fastNeutrino.{prefix}.{model}.npz",
    output:
        "simulations/pvalues/{prefix}.{model}.json"
    run:
        spectra_comp = load_spectra(input[0])
        spectra_null = load_spectra(input[1])
        results = scan_parameters(spectra_comp, spectra_null, pair_densities, max_ds, max_k, n_reps)
        with open(output[0], "w") as outfile:
            json.dump(results, outfile)

rule compute_pvalues_recombination:
    input:
        "simulations/msprime/fastNeutrino.{prefix}.{model}.rec={r_factor}.npz",
        "simulations/msprime/fastNeutrino.{prefix}.{model}.npz",
    output:
        "simulations/pvalues/{prefix}.{model}.rec={r_factor}.json"
    run:
        spectra_comp = load_spectra(input[0])
        spectra_null = load_spectra(input[1])
        results = scan_parameters(spectra_comp, spectra_null, pair_densities, max_ds, max_k, n_reps)
        with open(output[0], "w") as outfile:
            json.dump(results, outfile)

rule msprime_from_fastNeutrino:
    input:
        "simulations/fastNeutrino/{prefix}.txt"
    output:
        temp('simulations/.tmp/fastNeutrino.{prefix}.rep{rep}.npz')
    run:
        # Use Kingman parameters, but add demographic events properly scaled
        parameters = parameter_map('kingman', default_parameters)
        parameters['demographic_events'] = scaled_demographic_events(input[0])
        parameters['random_seed'] = filename2seed(output[0])
        spectra = simulate_spectra(parameters)
        spectra.save(output[0])


rule msprime_from_fastNeutrino_modified_recombination:
    input:
        "simulations/fastNeutrino/{prefix}.txt"
    output:
        temp('simulations/.tmp/fastNeutrino.{prefix}.rec={r_factor}.rep{rep}.npz')
    run:
        # Use Kingman parameters, but add demographic events properly scaled
        # modify recombination rate by r_factor
        # Use shorter sequences (25 bases)
        parameters = parameter_map('kingman', default_parameters)
        parameters['demographic_events'] = scaled_demographic_events(input[0])
        parameters['recombination_rate'] *= float(wildcards.r_factor)
        parameters['length'] = 25
        parameters['random_seed'] = filename2seed(output[0])
        spectra = simulate_spectra(parameters)
        spectra.save(output[0])

rule add_runs:
    output:
        'simulations/msprime/{prefix}.npz'
    input:
        expand('simulations/.tmp/{prefix}.rep{rep}.npz', rep=range(nruns), allow_missing=True)
    run:
        total = sum(load_spectra(infn) for infn in input)
        total.save(output[0])

rule fastNeutrino:
    input:
        datafile = "simulations/.tmp/{prefix}.sfs.txt",
        modelfile = "twosfs/models/{model}.txt"
    output:
        "simulations/fastNeutrino/{prefix}.{model}.txt"
    log:
        "log/fastNeutrino.{prefix}.{model}.log"
    shell:
        "fastNeutrino --maxB 20 --maxRandomRestarts 100 "
        "--modelFile {input.modelfile} "
        "--inferredModelOutputFile {output} "
        "< {input.datafile} "
        "> {log}"

rule fastNeutrinoInput:
    input:
        simulation_file = 'simulations/msprime/{prefix}.npz'
    output:
        sfs_file = temp("simulations/.tmp/{prefix}.sfs.txt")
    run:
        spectra = load_spectra(input.simulation_file)
        spectra.export_to_fastNeutrino(output.sfs_file)
